{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9xThAJ3Z-ti",
        "outputId": "9441b678-126c-4f0a-bfd8-9b2d1c7cdeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mt-exercise-4'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 49 (delta 8), reused 8 (delta 8), pack-reused 34\n",
            "Unpacking objects: 100% (49/49), 11.01 MiB | 7.96 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JeanKesselring/mt-exercise-4\n",
        "!cd mt-exercise-4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 -R mt-exercise-4"
      ],
      "metadata": {
        "id": "09nNETSzbmiP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd mt-exercise-4 && ./scripts/make_virtualenv.sh\n",
        "#!cd mt-exercise-4 && source venvs/torch3/bin/activate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XphJDF7bbGIP",
        "outputId": "d7c27a2a-e476-41a8-d765-5096b206b33a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./scripts/make_virtualenv.sh: Permission denied\n",
            "/bin/bash: venvs/torch3/bin/activate: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-4 && ./scripts/download_moses.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvDLpR3jazR8",
        "outputId": "2ce7d455-8004-41ef-979f-e5dc8006d625"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './scripts/../tools/moses-scripts'...\n",
            "remote: Enumerating objects: 147096, done.\u001b[K\n",
            "remote: Total 147096 (delta 0), reused 0 (delta 0), pack-reused 147096\u001b[K\n",
            "Receiving objects: 100% (147096/147096), 129.65 MiB | 18.85 MiB/s, done.\n",
            "Resolving deltas: 100% (113689/113689), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JeanKesselring/joeynmt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ8KJFpzckFE",
        "outputId": "856bd7f4-dc4c-4757-a26e-477d782fc3c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 4222, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 4222 (delta 85), reused 93 (delta 50), pack-reused 4064\u001b[K\n",
            "Receiving objects: 100% (4222/4222), 25.61 MiB | 19.55 MiB/s, done.\n",
            "Resolving deltas: 100% (2944/2944), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall setuptools\n",
        "!pip install setuptools==59.5.0\n",
        "!pip install torch==1.13.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-bDxHfJvc4RS",
        "outputId": "be98c874-efa9-4d7f-d567-b2141a5db814"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: setuptools 67.7.2\n",
            "Uninstalling setuptools-67.7.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/_distutils_hack/*\n",
            "    /usr/local/lib/python3.10/dist-packages/distutils-precedence.pth\n",
            "    /usr/local/lib/python3.10/dist-packages/pkg_resources/*\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools-67.7.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled setuptools-67.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-59.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (59.5.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd joeynmt && pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHt0YxAedaSg",
        "outputId": "71792f03-378f-4df1-fc37-cb61737357dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/joeynmt\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (0.18.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (1.22.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (59.5.0)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: protobuf<3.21,>=3.19.4 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (2.12.2)\n",
            "Collecting sacrebleu>=2.0.0 (from joeynmt==2.2.0)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from joeynmt==2.2.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting subword-nmt (from joeynmt==2.2.0)\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (0.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (6.0)\n",
            "Requirement already satisfied: six>=1.12 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (1.16.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (1.14.1)\n",
            "Collecting pylint (from joeynmt==2.2.0)\n",
            "  Downloading pylint-2.17.4-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yapf (from joeynmt==2.2.0)\n",
            "  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8 (from joeynmt==2.2.0)\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (7.2.2)\n",
            "Collecting datasets (from joeynmt==2.2.0)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (23.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from joeynmt==2.2.0) (5.13.1)\n",
            "Collecting portalocker (from sacrebleu>=2.0.0->joeynmt==2.2.0)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.2.0) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.2.0) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=2.0.0->joeynmt==2.2.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->joeynmt==2.2.0) (4.9.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->joeynmt==2.2.0) (0.40.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.2.0) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.2.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.2.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.2.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->joeynmt==2.2.0) (11.7.99)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.2.0) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->joeynmt==2.2.0)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.2.0) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.2.0) (4.65.0)\n",
            "Collecting xxhash (from datasets->joeynmt==2.2.0)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->joeynmt==2.2.0)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->joeynmt==2.2.0) (2023.4.0)\n",
            "Collecting aiohttp (from datasets->joeynmt==2.2.0)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets->joeynmt==2.2.0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets->joeynmt==2.2.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->joeynmt==2.2.0)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.11.0,>=2.10.0 (from flake8->joeynmt==2.2.0)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<3.1.0,>=3.0.0 (from flake8->joeynmt==2.2.0)\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.2.0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.2.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.2.0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.2.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.2.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->joeynmt==2.2.0) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->joeynmt==2.2.0) (8.2.2)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.2.0) (3.3.0)\n",
            "Collecting astroid<=2.17.0-dev0,>=2.15.4 (from pylint->joeynmt==2.2.0)\n",
            "  Downloading astroid-2.15.5-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort<6,>=4.2.5 (from pylint->joeynmt==2.2.0)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tomlkit>=0.10.1 (from pylint->joeynmt==2.2.0)\n",
            "  Downloading tomlkit-0.11.8-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->joeynmt==2.2.0) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.2.0) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.2.0) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->joeynmt==2.2.0) (1.1.1)\n",
            "Collecting mock (from subword-nmt->joeynmt==2.2.0)\n",
            "  Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n",
            "Collecting lazy-object-proxy>=1.4.0 (from astroid<=2.17.0-dev0,>=2.15.4->pylint->joeynmt==2.2.0)\n",
            "  Downloading lazy_object_proxy-1.9.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->joeynmt==2.2.0) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->joeynmt==2.2.0)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->joeynmt==2.2.0)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->joeynmt==2.2.0)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->joeynmt==2.2.0)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->joeynmt==2.2.0)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt==2.2.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt==2.2.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt==2.2.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->joeynmt==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->joeynmt==2.2.0) (3.12.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->joeynmt==2.2.0) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==2.2.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==2.2.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==2.2.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->joeynmt==2.2.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt==2.2.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->joeynmt==2.2.0) (3.2.2)\n",
            "Installing collected packages: sentencepiece, yapf, xxhash, tomlkit, pyflakes, pycodestyle, portalocker, multidict, mock, mccabe, lazy-object-proxy, isort, frozenlist, dill, colorama, async-timeout, yarl, subword-nmt, sacrebleu, responses, multiprocess, huggingface-hub, flake8, astroid, aiosignal, pylint, aiohttp, datasets, joeynmt\n",
            "  Running setup.py develop for joeynmt\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 astroid-2.15.5 async-timeout-4.0.2 colorama-0.4.6 datasets-2.12.0 dill-0.3.6 flake8-6.0.0 frozenlist-1.3.3 huggingface-hub-0.14.1 isort-5.12.0 joeynmt-2.2.0 lazy-object-proxy-1.9.0 mccabe-0.7.0 mock-5.0.2 multidict-6.0.4 multiprocess-0.70.14 portalocker-2.7.0 pycodestyle-2.10.0 pyflakes-3.0.1 pylint-2.17.4 responses-0.18.0 sacrebleu-2.3.1 sentencepiece-0.1.99 subword-nmt-0.3.8 tomlkit-0.11.8 xxhash-3.2.0 yapf-0.33.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_norm_config = \"\"\"name: \"deen_transformer_pre\"\n",
        "joeynmt_version: \"2.0.0\"\n",
        "\n",
        "data:\n",
        "    train: \"data/train\"\n",
        "    dev:   \"data/dev\"\n",
        "    test:  \"data/test\"\n",
        "    dataset_type: \"plain\"\n",
        "    src:\n",
        "        lang: \"de\"\n",
        "        lowercase: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 32000\n",
        "        voc_min_freq: 1\n",
        "        max_length: 100\n",
        "        voc_file: \"shared_models/joint-vocab.txt\"\n",
        "        tokenizer_type: \"subword-nmt\"\n",
        "        tokenizer_cfg:\n",
        "            pretokenizer: \"none\"\n",
        "            num_merges: 3200\n",
        "            codes: \"data/codes3200.bpe\"\n",
        "    trg: \n",
        "        lang: \"en\"\n",
        "        lowercase: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 32000\n",
        "        voc_min_freq: 1\n",
        "        max_length: 100\n",
        "        voc_file: \"shared_models/joint-vocab.txt\"\n",
        "        tokenizer_type: \"subword-nmt\"\n",
        "        tokenizer_cfg:\n",
        "            pretokenizer: \"none\"\n",
        "            num_merges: 3200\n",
        "            codes: \"data/codes3200.bpe\"\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    beam_alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"your/path.ckpt\"\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    learning_rate: 0.0003\n",
        "    batch_size: 2048\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 1024\n",
        "    eval_batch_type: \"token\"\n",
        "    scheduling: \"plateau\"\n",
        "    patience: 8\n",
        "    weight_decay: 0.0\n",
        "    decrease_factor: 0.7\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 10\n",
        "    validation_freq: 500\n",
        "    logging_freq: 100\n",
        "    eval_metric: [\"bleu\"]\n",
        "    model_dir: \"models/deen_transformer_pre\"\n",
        "    overwrite: False\n",
        "    shuffle: True\n",
        "    use_cuda: False\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3, 4]\n",
        "    label_smoothing: 0.3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier_uniform\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier_uniform\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    layer_norm: \"pre\"           # where to apply layer norm. either \"pre\" or \"post\". default \"post\"\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 4\n",
        "        num_heads: 2\n",
        "        embeddings:\n",
        "            embedding_dim: 256\n",
        "            scale: True\n",
        "            dropout: 0\n",
        "        hidden_size: 256\n",
        "        ff_size: 512\n",
        "        dropout: 0\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 1\n",
        "        num_heads: 2\n",
        "        embeddings:\n",
        "            embedding_dim: 256\n",
        "            scale: True\n",
        "            dropout: 0\n",
        "        hidden_size: 256\n",
        "        ff_size: 512\n",
        "        dropout: 0\n",
        "\"\"\"\n",
        "dir = \"mt-exercise-4/configs/\"\n",
        "with open(f\"{dir}pre_config.yaml\", \"w\")as file:\n",
        "  file = file.write(pre_norm_config)"
      ],
      "metadata": {
        "id": "MFVDXE1afFW5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_norm_config = \"\"\"name: \"deen_transformer_post\"\n",
        "joeynmt_version: \"2.0.0\"\n",
        "\n",
        "data:\n",
        "    train: \"data/train\"\n",
        "    dev:   \"data/dev\"\n",
        "    test:  \"data/test\"\n",
        "    dataset_type: \"plain\"\n",
        "    src:\n",
        "        lang: \"de\"\n",
        "        lowercase: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 32000\n",
        "        voc_min_freq: 1\n",
        "        max_length: 100\n",
        "        voc_file: \"shared_models/joint-vocab.txt\"\n",
        "        tokenizer_type: \"subword-nmt\"\n",
        "        tokenizer_cfg:\n",
        "            pretokenizer: \"none\"\n",
        "            num_merges: 3200\n",
        "            codes: \"data/codes3200.bpe\"\n",
        "    trg: \n",
        "        lang: \"en\"\n",
        "        lowercase: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 32000\n",
        "        voc_min_freq: 1\n",
        "        max_length: 100\n",
        "        voc_file: \"shared_models/joint-vocab.txt\"\n",
        "        tokenizer_type: \"subword-nmt\"\n",
        "        tokenizer_cfg:\n",
        "            pretokenizer: \"none\"\n",
        "            num_merges: 3200\n",
        "            codes: \"data/codes3200.bpe\"\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    beam_alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"your/path.ckpt\"\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    learning_rate: 0.0003\n",
        "    batch_size: 2048\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 1024\n",
        "    eval_batch_type: \"token\"\n",
        "    scheduling: \"plateau\"\n",
        "    patience: 8\n",
        "    weight_decay: 0.0\n",
        "    decrease_factor: 0.7\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 10\n",
        "    validation_freq: 500\n",
        "    logging_freq: 100\n",
        "    eval_metric: [\"bleu\"]\n",
        "    model_dir: \"models/deen_transformer_pre\"\n",
        "    overwrite: False\n",
        "    shuffle: True\n",
        "    use_cuda: False\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3, 4]\n",
        "    label_smoothing: 0.3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier_uniform\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier_uniform\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    layer_norm: \"post\"           # where to apply layer norm. either \"pre\" or \"post\". default \"post\"\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 4\n",
        "        num_heads: 2\n",
        "        embeddings:\n",
        "            embedding_dim: 256\n",
        "            scale: True\n",
        "            dropout: 0\n",
        "        hidden_size: 256\n",
        "        ff_size: 512\n",
        "        dropout: 0\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 1\n",
        "        num_heads: 2\n",
        "        embeddings:\n",
        "            embedding_dim: 256\n",
        "            scale: True\n",
        "            dropout: 0\n",
        "        hidden_size: 256\n",
        "        ff_size: 512\n",
        "        dropout: 0\n",
        "\"\"\"\n",
        "dir = \"mt-exercise-4/configs/\"\n",
        "with open(f\"{dir}post_config.yaml\", \"w\")as file:\n",
        "  file = file.write(post_norm_config)"
      ],
      "metadata": {
        "id": "McFLnfu7fr1a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-4 && python -m joeynmt train configs/post_config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV_i29IekmcO",
        "outputId": "30d49ff1-9dc4-4167-fb27-2479ab69e174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-16 08:01:14,158 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).\n",
            "2023-05-16 08:01:14,158 - INFO - joeynmt.helpers -                           cfg.name : deen_transformer_pre\n",
            "2023-05-16 08:01:14,158 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0\n",
            "2023-05-16 08:01:14,158 - INFO - joeynmt.helpers -                     cfg.data.train : data/train\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -                      cfg.data.test : data/test\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 32000\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -          cfg.data.src.voc_min_freq : 1\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -            cfg.data.src.max_length : 100\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : shared_models/joint-vocab.txt\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 3200\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/codes3200.bpe\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 32000\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -          cfg.data.trg.voc_min_freq : 1\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -            cfg.data.trg.max_length : 100\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : shared_models/joint-vocab.txt\n",
            "2023-05-16 08:01:14,159 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 3200\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/codes3200.bpe\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -             cfg.testing.beam_alpha : 1.0\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -            cfg.training.batch_type : token\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -              cfg.training.patience : 8\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -                cfg.training.epochs : 10\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -           cfg.training.eval_metric : ['bleu']\n",
            "2023-05-16 08:01:14,160 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/deen_transformer_pre\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -             cfg.training.overwrite : False\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -               cfg.training.shuffle : True\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -               cfg.model.layer_norm : post\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256\n",
            "2023-05-16 08:01:14,161 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512\n",
            "2023-05-16 08:01:14,162 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0\n",
            "2023-05-16 08:01:14,164 - INFO - joeynmt.data - Building tokenizer...\n",
            "2023-05-16 08:01:14,186 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)\n",
            "2023-05-16 08:01:14,187 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)\n",
            "2023-05-16 08:01:14,187 - INFO - joeynmt.data - Loading train set...\n",
            "2023-05-16 08:01:15,042 - INFO - joeynmt.data - Building vocabulary...\n",
            "2023-05-16 08:01:15,261 - INFO - joeynmt.data - Loading dev set...\n",
            "2023-05-16 08:01:15,266 - INFO - joeynmt.data - Loading test set...\n",
            "2023-05-16 08:01:15,282 - INFO - joeynmt.data - Data loaded.\n",
            "2023-05-16 08:01:15,283 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=de, trg_lang=en, has_trg=True, random_subset=-1)\n",
            "2023-05-16 08:01:15,283 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=500, src_lang=de, trg_lang=en, has_trg=True, random_subset=-1)\n",
            "2023-05-16 08:01:15,283 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=2999, src_lang=de, trg_lang=en, has_trg=True, random_subset=-1)\n",
            "2023-05-16 08:01:15,285 - INFO - joeynmt.data - First training example:\n",
            "\t[SRC] gem@@ ä@@ ß der vom Europäischen Parlament und von der gesam@@ ten Europäischen Union n@@ un@@ mehr ständi@@ g ver@@ tre@@ ten@@ en Lin@@ ie möchte ich Sie jedoch bit@@ ten , den gan@@ zen Ein@@ f@@ lu@@ ß Ih@@ res Am@@ tes und der Institu@@ tion , die Sie ver@@ treten , bei dem Prä@@ sident@@ schaf@@ ts@@ kan@@ di@@ d@@ aten und G@@ ou@@ ver@@ ne@@ ur von Tex@@ as , Ge@@ or@@ ge W@@ . B@@ us@@ h , der zur Aus@@ setzung der V@@ oll@@ stre@@ ck@@ ung des To@@ des@@ ur@@ teil@@ s und zur Be@@ gn@@ a@@ di@@ gung des Ver@@ ur@@ teil@@ ten be@@ fu@@ gt ist , gel@@ ten@@ d zu machen .\n",
            "\t[TRG] however , I would ask you , in acc@@ ord@@ ance with the line which is now con@@ st@@ ant@@ ly fol@@ low@@ ed by the European Parliament and by the whole of the European Community , to make represent@@ ations , using the wei@@ ght of your pres@@ ti@@ gi@@ ous off@@ ice and the institu@@ tion you re@@ present , to the President and to the Go@@ vern@@ or of Tex@@ as , Mr B@@ us@@ h , who has the power to order a stay of ex@@ ec@@ ution and to re@@ pri@@ e@@ ve the con@@ dem@@ ned per@@ son .\n",
            "2023-05-16 08:01:15,286 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) die (9) der\n",
            "2023-05-16 08:01:15,286 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) die (9) der\n",
            "2023-05-16 08:01:15,286 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 4117\n",
            "2023-05-16 08:01:15,286 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 4117\n",
            "2023-05-16 08:01:15,288 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2023-05-16 08:01:15,406 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2023-05-16 08:01:17.372955: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-16 08:01:20.358975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-16 08:01:24,200 - INFO - numexpr.utils - NumExpr defaulting to 2 threads.\n",
            "2023-05-16 08:01:25,076 - INFO - joeynmt.model - Total params: 3953152\n",
            "2023-05-16 08:01:25,079 - INFO - joeynmt.training - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm=\"pre\", activation=ReLU()),\n",
            "\tdecoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm=\"post\", activation=ReLU()),\n",
            "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=4117),\n",
            "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=4117),\n",
            "\tloss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))\n",
            "2023-05-16 08:01:25,080 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))\n",
            "2023-05-16 08:01:25,080 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)\n",
            "2023-05-16 08:01:25,081 - INFO - joeynmt.training - Train stats:\n",
            "\tdevice: cpu\n",
            "\tn_gpu: 0\n",
            "\t16-bits training: False\n",
            "\tgradient accumulation: 1\n",
            "\tbatch size per device: 2048\n",
            "\teffective batch size (w. parallel & accumulation): 2048\n",
            "2023-05-16 08:01:25,081 - INFO - joeynmt.training - EPOCH 1\n",
            "2023-05-16 08:03:58,217 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.264142, Batch Acc: 0.050576, Tokens per Sec:      601, Lr: 0.000300\n",
            "2023-05-16 08:06:29,213 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.166991, Batch Acc: 0.082179, Tokens per Sec:      611, Lr: 0.000300\n",
            "2023-05-16 08:09:07,701 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.085839, Batch Acc: 0.090181, Tokens per Sec:      584, Lr: 0.000300\n",
            "2023-05-16 08:11:32,767 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.974140, Batch Acc: 0.089457, Tokens per Sec:      632, Lr: 0.000300\n",
            "2023-05-16 08:14:12,275 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.900661, Batch Acc: 0.096440, Tokens per Sec:      582, Lr: 0.000300\n",
            "2023-05-16 08:14:12,276 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [05:55<00:00,  1.40it/s]\n",
            "2023-05-16 08:20:08,296 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.05, ppl:  57.27, acc:   0.09, generation: 356.0039[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 08:20:08,297 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 08:20:08,415 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 08:20:08,416 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 08:20:08,416 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 08:20:08,416 - INFO - joeynmt.training - \tHypothesis: the rererererererererererererererecccccccccccccccccccccccccccccced .\n",
            "2023-05-16 08:20:08,416 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 08:20:08,417 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 08:20:08,417 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 08:20:08,417 - INFO - joeynmt.training - \tHypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the , the cccccccccccccccccccccccccccccccccccced , the c, the cced , the c.\n",
            "2023-05-16 08:20:08,417 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - \tHypothesis: the recccccccced , the reced , the reced , the reced , the reced , the reced , the reced , the recced , the the the the the reced .\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 08:20:08,418 - INFO - joeynmt.training - \tHypothesis: the rererererererererererererereccccccccccccccccccccccccccccccccced .\n",
            "2023-05-16 08:20:08,419 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 08:20:08,419 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 08:20:08,419 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 08:20:08,419 - INFO - joeynmt.training - \tHypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the reced .\n",
            "2023-05-16 08:22:38,299 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.871942, Batch Acc: 0.100587, Tokens per Sec:      625, Lr: 0.000300\n",
            "2023-05-16 08:25:04,417 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.797830, Batch Acc: 0.102503, Tokens per Sec:      633, Lr: 0.000300\n",
            "2023-05-16 08:27:37,455 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.792605, Batch Acc: 0.102682, Tokens per Sec:      598, Lr: 0.000300\n",
            "2023-05-16 08:30:16,810 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.716628, Batch Acc: 0.104477, Tokens per Sec:      570, Lr: 0.000300\n",
            "2023-05-16 08:32:49,491 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.693542, Batch Acc: 0.102014, Tokens per Sec:      616, Lr: 0.000300\n",
            "2023-05-16 08:32:49,492 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [06:40<00:00,  1.25it/s]\n",
            "2023-05-16 08:39:30,166 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.96, ppl:  52.36, acc:   0.09, generation: 400.6528[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 08:39:30,181 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 08:39:30,328 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 08:39:30,329 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 08:39:30,329 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 08:39:30,329 - INFO - joeynmt.training - \tHypothesis: the .\n",
            "2023-05-16 08:39:30,329 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 08:39:30,330 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 08:39:30,331 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 08:39:30,331 - INFO - joeynmt.training - \tHypothesis: the European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European , the the European European European European European , the the European European European European European European European European European European European European European European European , the the the the the the the the the the the the European S----eced .\n",
            "2023-05-16 08:39:30,331 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 08:39:30,332 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 08:39:30,332 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 08:39:30,333 - INFO - joeynmt.training - \tHypothesis: the . , the European European European European European European European European European European European European European .\n",
            "2023-05-16 08:39:30,333 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 08:39:30,333 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 08:39:30,333 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 08:39:30,334 - INFO - joeynmt.training - \tHypothesis: the .\n",
            "2023-05-16 08:39:30,334 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 08:39:30,334 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 08:39:30,334 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 08:39:30,335 - INFO - joeynmt.training - \tHypothesis: the . , the . , the .\n",
            "2023-05-16 08:41:58,417 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.796343, Batch Acc: 0.103834, Tokens per Sec:      620, Lr: 0.000300\n",
            "2023-05-16 08:44:25,776 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.813947, Batch Acc: 0.105918, Tokens per Sec:      628, Lr: 0.000300\n",
            "2023-05-16 08:46:53,686 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.693859, Batch Acc: 0.107711, Tokens per Sec:      622, Lr: 0.000300\n",
            "2023-05-16 08:49:22,410 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.693471, Batch Acc: 0.110161, Tokens per Sec:      615, Lr: 0.000300\n",
            "2023-05-16 08:51:48,873 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.649117, Batch Acc: 0.112377, Tokens per Sec:      621, Lr: 0.000300\n",
            "2023-05-16 08:51:48,874 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [07:24<00:00,  1.13it/s]\n",
            "2023-05-16 08:59:13,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.87, ppl:  47.86, acc:   0.10, generation: 444.2426[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 08:59:13,135 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 08:59:13,229 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 08:59:13,229 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 08:59:13,230 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 08:59:13,230 - INFO - joeynmt.training - \tHypothesis: the Cya . the Cya .\n",
            "2023-05-16 08:59:13,230 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 08:59:13,230 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 08:59:13,230 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 08:59:13,231 - INFO - joeynmt.training - \tHypothesis: the C-, the C-, the C-, the C-, the C-, the C-, the C-, the C-and the C-, the C-, the C-, the re-, and the C-, and the re-and the C-, and the C-and the C-, and the reAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
            "2023-05-16 08:59:13,231 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 08:59:13,231 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 08:59:13,231 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 08:59:13,231 - INFO - joeynmt.training - \tHypothesis: the European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European European States .\n",
            "2023-05-16 08:59:13,231 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 08:59:13,232 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 08:59:13,232 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 08:59:13,232 - INFO - joeynmt.training - \tHypothesis: the repes , the repa is is is is is the repy .\n",
            "2023-05-16 08:59:13,232 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 08:59:13,233 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 08:59:13,233 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 08:59:13,233 - INFO - joeynmt.training - \tHypothesis: I have be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be\n",
            "2023-05-16 09:01:41,663 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.666295, Batch Acc: 0.114131, Tokens per Sec:      628, Lr: 0.000300\n",
            "2023-05-16 09:04:06,248 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.633194, Batch Acc: 0.120581, Tokens per Sec:      629, Lr: 0.000300\n",
            "2023-05-16 09:06:33,150 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.646851, Batch Acc: 0.121082, Tokens per Sec:      624, Lr: 0.000300\n",
            "2023-05-16 09:08:55,319 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.556988, Batch Acc: 0.131383, Tokens per Sec:      647, Lr: 0.000300\n",
            "2023-05-16 09:11:13,933 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.379853, Batch Acc: 0.138773, Tokens per Sec:      660, Lr: 0.000300\n",
            "2023-05-16 09:11:13,934 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [06:08<00:00,  1.36it/s]\n",
            "2023-05-16 09:17:22,607 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.71, ppl:  40.99, acc:   0.12, generation: 368.6517[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 09:17:22,608 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 09:17:22,745 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 09:17:22,746 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 09:17:22,746 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 09:17:22,746 - INFO - joeynmt.training - \tHypothesis: the Cyya , the Cya , and the Cya , and the Cya .\n",
            "2023-05-16 09:17:22,747 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 09:17:22,748 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 09:17:22,748 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 09:17:22,748 - INFO - joeynmt.training - \tHypothesis: the Commission of the Commission of the Commission of the Commission of the Commission of the conconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconconvt .\n",
            "2023-05-16 09:17:22,748 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 09:17:22,749 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 09:17:22,749 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 09:17:22,749 - INFO - joeynmt.training - \tHypothesis: Mr President , the Commission , the Commission , the Commission , the Commission of the Commission , and the Commission of the Commission of the Commission of the European Union .\n",
            "2023-05-16 09:17:22,749 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 09:17:22,750 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 09:17:22,750 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 09:17:22,750 - INFO - joeynmt.training - \tHypothesis: the Commission of the Commission of the Commission of the Commission of the Commission of the Commission .\n",
            "2023-05-16 09:17:22,750 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 09:17:22,751 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 09:17:22,751 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 09:17:22,751 - INFO - joeynmt.training - \tHypothesis: the Commission of the Commission of the Commission of the Commission of the Commission of the Commission .\n",
            "2023-05-16 09:19:45,305 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.385278, Batch Acc: 0.153738, Tokens per Sec:      645, Lr: 0.000300\n",
            "2023-05-16 09:22:09,119 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.306864, Batch Acc: 0.168637, Tokens per Sec:      635, Lr: 0.000300\n",
            "2023-05-16 09:24:30,953 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.367287, Batch Acc: 0.181685, Tokens per Sec:      643, Lr: 0.000300\n",
            "2023-05-16 09:26:47,507 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.239701, Batch Acc: 0.196934, Tokens per Sec:      657, Lr: 0.000300\n",
            "2023-05-16 09:29:11,692 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.169841, Batch Acc: 0.202714, Tokens per Sec:      624, Lr: 0.000300\n",
            "2023-05-16 09:29:11,693 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [06:55<00:00,  1.20it/s]\n",
            "2023-05-16 09:36:07,467 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.42, ppl:  30.48, acc:   0.16, generation: 415.7585[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 09:36:07,485 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 09:36:07,581 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - \tHypothesis: the Caaaaaaaaaaain the bbbon the bourt .\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 09:36:07,582 - INFO - joeynmt.training - \tHypothesis: the CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa.\n",
            "2023-05-16 09:36:07,583 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 09:36:07,583 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 09:36:07,583 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 09:36:07,583 - INFO - joeynmt.training - \tHypothesis: Mr President , the most important of the most important of the most important of the most important of the most important of the most important of the most the most important of the most important .\n",
            "2023-05-16 09:36:07,583 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - \tHypothesis: the European Union is a new time of the European Union .\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 09:36:07,584 - INFO - joeynmt.training - \tHypothesis: the most important of the European Union , the European Union is a new time .\n",
            "2023-05-16 09:38:40,822 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     3.004674, Batch Acc: 0.211154, Tokens per Sec:      603, Lr: 0.000300\n",
            "2023-05-16 09:41:03,482 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     3.058957, Batch Acc: 0.217723, Tokens per Sec:      648, Lr: 0.000300\n",
            "2023-05-16 09:43:25,994 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     3.045096, Batch Acc: 0.220583, Tokens per Sec:      645, Lr: 0.000300\n",
            "2023-05-16 09:45:50,199 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     3.033135, Batch Acc: 0.226908, Tokens per Sec:      633, Lr: 0.000300\n",
            "2023-05-16 09:48:12,444 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.882121, Batch Acc: 0.232240, Tokens per Sec:      648, Lr: 0.000300\n",
            "2023-05-16 09:48:12,444 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [04:58<00:00,  1.67it/s]\n",
            "2023-05-16 09:53:11,194 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.27, ppl:  26.31, acc:   0.18, generation: 298.7370[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 09:53:11,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 09:53:11,303 - INFO - joeynmt.helpers - delete models/deen_transformer_pre/500.ckpt\n",
            "2023-05-16 09:53:11,314 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 09:53:11,314 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 09:53:11,314 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 09:53:11,315 - INFO - joeynmt.training - \tHypothesis: the cyle and the cyle and the Chistory .\n",
            "2023-05-16 09:53:11,315 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 09:53:11,315 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 09:53:11,315 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 09:53:11,315 - INFO - joeynmt.training - \tHypothesis: the CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCyyyle .\n",
            "2023-05-16 09:53:11,315 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 09:53:11,316 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 09:53:11,316 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 09:53:11,316 - INFO - joeynmt.training - \tHypothesis: Mr President , the most important of the European Union , the realist of the European Union , the European Union , the European Union , the EU &apos;s property of the European Union .\n",
            "2023-05-16 09:53:11,316 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - \tHypothesis: the European Union is the European Union to the European Union .\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 09:53:11,317 - INFO - joeynmt.training - \tHypothesis: the European Union is a clear clear clear the European Union &apos;s property of the European Union .\n",
            "2023-05-16 09:55:38,419 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.914729, Batch Acc: 0.240041, Tokens per Sec:      631, Lr: 0.000300\n",
            "2023-05-16 09:58:02,588 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.771710, Batch Acc: 0.244447, Tokens per Sec:      632, Lr: 0.000300\n",
            "2023-05-16 10:00:25,826 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.868502, Batch Acc: 0.248984, Tokens per Sec:      637, Lr: 0.000300\n",
            "2023-05-16 10:02:49,071 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.727910, Batch Acc: 0.253390, Tokens per Sec:      649, Lr: 0.000300\n",
            "2023-05-16 10:05:15,246 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.734820, Batch Acc: 0.251287, Tokens per Sec:      627, Lr: 0.000300\n",
            "2023-05-16 10:05:15,246 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [06:18<00:00,  1.32it/s]\n",
            "2023-05-16 10:11:33,494 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.17, ppl:  23.93, acc:   0.20, generation: 378.2376[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 10:11:33,514 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 10:11:33,623 - INFO - joeynmt.helpers - delete models/deen_transformer_pre/1000.ckpt\n",
            "2023-05-16 10:11:33,638 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 10:11:33,638 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 10:11:33,638 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 10:11:33,639 - INFO - joeynmt.training - \tHypothesis: the Casa and September .\n",
            "2023-05-16 10:11:33,639 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 10:11:33,639 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 10:11:33,639 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 10:11:33,639 - INFO - joeynmt.training - \tHypothesis: the Casa , the Casa , the Court of the first of the first of the first of the first of the Court of the Chrisisisisished in the Court of the Casa , and the Chrisisisistics of the Chrisistititititititititititititian in the Car of the Catory of the world .\n",
            "2023-05-16 10:11:33,639 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 10:11:33,640 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 10:11:33,640 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 10:11:33,640 - INFO - joeynmt.training - \tHypothesis: Mr President , the most important of the most important of the most important of the economic economic economic and the economic economic economic economic and the most important of the world .\n",
            "2023-05-16 10:11:33,640 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - \tHypothesis: the first of the EU must be able to the EU to the EU &apos;s &apos;s projects .\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 10:11:33,641 - INFO - joeynmt.training - \tHypothesis: the rapporteur &apos;s report , the rapporteur &apos;s report on the EU &apos;s report on the EU &apos;s proposal .\n",
            "2023-05-16 10:14:00,230 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     3.063491, Batch Acc: 0.256409, Tokens per Sec:      629, Lr: 0.000300\n",
            "2023-05-16 10:16:30,167 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.705505, Batch Acc: 0.256765, Tokens per Sec:      616, Lr: 0.000300\n",
            "2023-05-16 10:18:54,500 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.833709, Batch Acc: 0.263102, Tokens per Sec:      640, Lr: 0.000300\n",
            "2023-05-16 10:21:19,559 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.727843, Batch Acc: 0.267202, Tokens per Sec:      641, Lr: 0.000300\n",
            "2023-05-16 10:23:47,027 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.644719, Batch Acc: 0.272468, Tokens per Sec:      625, Lr: 0.000300\n",
            "2023-05-16 10:23:47,028 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...: 100% 500/500 [06:17<00:00,  1.32it/s]\n",
            "2023-05-16 10:30:04,446 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.09, ppl:  22.06, acc:   0.22, generation: 377.4055[sec], evaluation: 0.0000[sec]\n",
            "2023-05-16 10:30:04,461 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2023-05-16 10:30:04,568 - INFO - joeynmt.helpers - delete models/deen_transformer_pre/1500.ckpt\n",
            "2023-05-16 10:30:04,580 - INFO - joeynmt.training - Example #0\n",
            "2023-05-16 10:30:04,580 - INFO - joeynmt.training - \tSource:     die Premierminister Indiens und Japans trafen sich in Tokio .\n",
            "2023-05-16 10:30:04,581 - INFO - joeynmt.training - \tReference:  India and Japan prime ministers meet in Tokyo\n",
            "2023-05-16 10:30:04,581 - INFO - joeynmt.training - \tHypothesis: the Cio and and and the camera .\n",
            "2023-05-16 10:30:04,581 - INFO - joeynmt.training - Example #1\n",
            "2023-05-16 10:30:04,581 - INFO - joeynmt.training - \tSource:     Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko , um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen .\n",
            "2023-05-16 10:30:04,582 - INFO - joeynmt.training - \tReference:  India &apos;s new prime minister , Narendra Modi , is meeting his Japanese counterpart , Shinzo Abe , in Tokyo to discuss economic and security ties , on his first major foreign visit since winning May &apos;s election .\n",
            "2023-05-16 10:30:04,582 - INFO - joeynmt.training - \tHypothesis: the Caaaaaaaay of the most important important important important important important important important in the most important of the most important of the world of the Court of the world and the reform of the world of the reform of the economic and social and social and social and the reform of the world .\n",
            "2023-05-16 10:30:04,582 - INFO - joeynmt.training - Example #2\n",
            "2023-05-16 10:30:04,582 - INFO - joeynmt.training - \tSource:     Herr Modi befindet sich auf einer fünftägigen Reise nach Japan , um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen .\n",
            "2023-05-16 10:30:04,582 - INFO - joeynmt.training - \tReference:  Mr Modi is on a five @-@ day trip to Japan to strengthen economic ties with the third largest economy in the world .\n",
            "2023-05-16 10:30:04,582 - INFO - joeynmt.training - \tHypothesis: Mr President , the most important of the world of the world , the most important of the world of the world of the world of the world of the world of the world .\n",
            "2023-05-16 10:30:04,583 - INFO - joeynmt.training - Example #3\n",
            "2023-05-16 10:30:04,583 - INFO - joeynmt.training - \tSource:     Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung .\n",
            "2023-05-16 10:30:04,583 - INFO - joeynmt.training - \tReference:  high on the agenda are plans for greater nuclear co @-@ operation .\n",
            "2023-05-16 10:30:04,583 - INFO - joeynmt.training - \tHypothesis: the new new new new development of the development of the development of the development of the development of the European level .\n",
            "2023-05-16 10:30:04,583 - INFO - joeynmt.training - Example #4\n",
            "2023-05-16 10:30:04,584 - INFO - joeynmt.training - \tSource:     Berichten zufolge hofft Indien darüber hinaus auf einen Vertrag zur Verteidigungszusammenarbeit zwischen den beiden Nationen .\n",
            "2023-05-16 10:30:04,584 - INFO - joeynmt.training - \tReference:  India is also reportedly hoping for a deal on defence collaboration between the two nations .\n",
            "2023-05-16 10:30:04,584 - INFO - joeynmt.training - \tHypothesis: the report has been made by the Committee on the Committee on the Committee on the Committee on the Committee on the Committee on the EU .\n",
            "2023-05-16 10:31:34,686 - INFO - joeynmt.training - Epoch   1: total training loss 13792.60\n",
            "2023-05-16 10:31:34,686 - INFO - joeynmt.training - EPOCH 2\n",
            "2023-05-16 10:32:24,992 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     2.711899, Batch Acc: 0.277883, Tokens per Sec:      660, Lr: 0.000300\n",
            "2023-05-16 10:34:47,921 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.719730, Batch Acc: 0.280044, Tokens per Sec:      646, Lr: 0.000300\n",
            "2023-05-16 10:37:15,312 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.625036, Batch Acc: 0.284729, Tokens per Sec:      616, Lr: 0.000300\n",
            "2023-05-16 10:39:39,328 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.791605, Batch Acc: 0.286555, Tokens per Sec:      641, Lr: 0.000300\n",
            "2023-05-16 10:42:00,096 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.778445, Batch Acc: 0.289804, Tokens per Sec:      658, Lr: 0.000300\n",
            "2023-05-16 10:42:00,097 - INFO - joeynmt.prediction - Predicting 500 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)\n",
            "Predicting...:  93% 465/500 [05:04<00:18,  1.87it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-4 && python -m joeynmt train configs/pre_config.yaml"
      ],
      "metadata": {
        "id": "l_7gWcIflCOi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}